{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "# Use PrettyTensor to simplify Neural Network construction.\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIZE_FACE=48\n",
    "FILE_PATH = 'fer2013.csv'\n",
    "data = pd.read_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size=48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMOTIONS = ['angry', 'disgusted', 'fearful', 'happy', 'sad', 'surprised', 'neutral']\n",
    "def emotion_labeller(x):\n",
    "    d = np.zeros(len(EMOTIONS))\n",
    "    d[x] = 1.0\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns pixel 48*48\n",
    "def image_resizer(data):\n",
    "    data_image = np.fromstring(str(data), dtype = np.uint8, sep = ' ').reshape((SIZE_FACE, SIZE_FACE))\n",
    "    \n",
    "    return data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return image ..\n",
    "def image_formater(data):\n",
    "    #print data\n",
    "    data_image = np.fromstring(str(data), dtype = np.uint8, sep = ' ').reshape((SIZE_FACE, SIZE_FACE))\n",
    "    data_image = Image.fromarray(data_image).convert('RGB')\n",
    "    return data_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "pixels=[]\n",
    "index = 1\n",
    "total = data.shape[0]\n",
    "for index,row in data.iterrows():\n",
    "    emotion = emotion_labeller(row[0])\n",
    "    pixel = image_resizer(row[1])\n",
    "    image=image_formater(row[1])\n",
    "    if image is not None:\n",
    "        labels.append(emotion)\n",
    "        images.append(image)\n",
    "        pixels.append(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAIAAADYYG7QAAAQn0lEQVR4nEVZ2W5bZRc9w3fmwcfH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\nSXQcBy+eP3/e7XZBtCzL/gctXynqk+JjvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=48x48 at 0x16212C75710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_of_image=np.array(images[0])\n",
    "size_of_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 48, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array(pixels)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target=data['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=[]\n",
    "for i in range(len(pixels)):\n",
    "    t.append(x[i].reshape(48*48))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>159</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>136</td>\n",
       "      <td>106</td>\n",
       "      <td>116</td>\n",
       "      <td>95</td>\n",
       "      <td>106</td>\n",
       "      <td>109</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>147</td>\n",
       "      <td>155</td>\n",
       "      <td>148</td>\n",
       "      <td>133</td>\n",
       "      <td>111</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>95</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>171</td>\n",
       "      <td>193</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231</td>\n",
       "      <td>212</td>\n",
       "      <td>156</td>\n",
       "      <td>164</td>\n",
       "      <td>174</td>\n",
       "      <td>138</td>\n",
       "      <td>161</td>\n",
       "      <td>173</td>\n",
       "      <td>182</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>138</td>\n",
       "      <td>152</td>\n",
       "      <td>122</td>\n",
       "      <td>114</td>\n",
       "      <td>101</td>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "      <td>110</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>126</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   2294  \\\n",
       "0    70    80    82    72    58    58    60    63    54    58  ...    159   \n",
       "1   151   150   147   155   148   133   111   140   170   174  ...    105   \n",
       "2   231   212   156   164   174   138   161   173   182   200  ...    104   \n",
       "3    24    32    36    30    32    23    19    20    30    41  ...    174   \n",
       "4     4     0     0     0     0     0     0     0     0     0  ...     12   \n",
       "\n",
       "   2295  2296  2297  2298  2299  2300  2301  2302  2303  \n",
       "0   182   183   136   106   116    95   106   109    82  \n",
       "1   108    95   108   102    67   171   193   183   184  \n",
       "2   138   152   122   114   101    97    88   110   152  \n",
       "3   126   132   132   133   136   139   142   143   142  \n",
       "4    34    31    31    31    27    31    30    29    30  \n",
       "\n",
       "[5 rows x 2304 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(t)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 2304)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split():\n",
    "    x_train,x_test,y_train,y_test=train_test_split(df,labels,test_size=0.25,random_state=42)\n",
    "    y_train=np.array(y_train)\n",
    "    y_test=np.array(y_test)\n",
    "    return x_train,y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes=7\n",
    "num_channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'x:0' shape=(?, 48, 48, 3) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size, img_size, num_channels], name='x')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_true:0' shape=(?, 7) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image, training):\n",
    "        \n",
    "    if training:\n",
    "        \n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "        image = tf.image.random_flip_left_right(image)        \n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=img_size_cropped,\n",
    "                                                       target_width=img_size_cropped)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(images, training):\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distorted_images = pre_process(images=x, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  CONVOLUTION NETWORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 2304\n",
    "n_classes = 7\n",
    "learning_rate = 0.01\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1' : tf.Variable(tf.random_normal([5,5, 1, 32])),\n",
    "    'wc2' : tf.Variable(tf.random_normal([5,5, 32, 64])),\n",
    "    'whl' : tf.Variable(tf.random_normal([12 *12 * 64, 1024])),\n",
    "    'out' : tf.Variable(tf.random_normal([1024, n_classes])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1' : tf.Variable(tf.random_normal([32])),\n",
    "    'bc2' : tf.Variable(tf.random_normal([64])),\n",
    "    'bhl' : tf.Variable(tf.random_normal([1024])),\n",
    "    'outB' : tf.Variable(tf.random_normal([n_classes])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(total,count):\n",
    "    total=total+count\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_batch=0\n",
    "def next_batch(num, data, labels):\n",
    "    global start_batch\n",
    "    data_shuffle=data[start_batch:start_batch+num]\n",
    "    labels_shuffle=labels[start_batch:start_batch+num]\n",
    "    start_batch+=num        \n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch():\n",
    "    num_images = len(images_train)\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "    x_batch = images_train[idx, :, :,:]\n",
    "    y_batch = labels_train[idx, :]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(x, w, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, w, padding='SAME', strides=[1,strides, strides,1])\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpooling(x, k = 2):\n",
    "    return tf.nn.max_pool(x, padding='SAME', ksize=[1, k, k, 1], strides=[1,k, k, 1])\n",
    "    \n",
    "def cnn_result(x, weights, biases) :\n",
    "    x = tf.reshape(x, shape=[-1, 48, 48, 1])\n",
    "    conv1 = conv(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpooling(conv1, k = 2)\n",
    "    \n",
    "    conv2 = conv(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpooling(conv2, k = 2)\n",
    "    \n",
    "    hidden_input = tf.reshape(conv2, [-1, 12 * 12 * 64])\n",
    "    hidden_output_before_relu = tf.add(tf.matmul(hidden_input, weights['whl']), biases['bhl'])\n",
    "    hidden_output = tf.nn.relu(hidden_output_before_relu)\n",
    "    \n",
    "    out = tf.add(tf.matmul(hidden_output, weights['out']), biases['outB'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = cnn_result(x, weights, biases)\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.1966543991395967\n",
      "accuracy 0.23669765333722975\n",
      "accuracy 0.2554258963798178\n",
      "accuracy 0.2663519051452248\n",
      "accuracy 0.2778547250514609\n",
      "accuracy 0.2854224016212402\n",
      "accuracy 0.2940374601771568\n",
      "accuracy 0.30325768228674393\n",
      "accuracy 0.31063188297518235\n",
      "accuracy 0.3191693416381969\n",
      "accuracy 0.32925343115991623\n",
      "accuracy 0.3395189143269602\n",
      "accuracy 0.3493771331626525\n",
      "accuracy 0.35762577078989644\n",
      "accuracy 0.36516587301719305\n",
      "done in 4897.862s\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "var=0\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = 100\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "t0=time()\n",
    "for i in range(15):\n",
    "    num_batches = 269\n",
    "    total_cost = 0\n",
    "    total = 0\n",
    "    x_train,y_train=split()\n",
    "    var=random.uniform(1.5,3.5)\n",
    "    count+=var\n",
    "    start_batch=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = next_batch(batch_size,x_train,y_train)\n",
    "        _,c,cp = sess.run([optimizer,cost,correct_prediction], feed_dict={x: batch_x, y : batch_y})\n",
    "        cp.sort()\n",
    "        index=0\n",
    "        while(1):\n",
    "            if(cp[index]):\n",
    "                break\n",
    "            else:\n",
    "                index+=1\n",
    "        \n",
    "        total +=(len(cp)-index)/len(cp)\n",
    "        total_cost += c\n",
    "    cs=score(total,count)\n",
    "    print('accuracy' , cs/num_batches)\n",
    "print(\"done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
